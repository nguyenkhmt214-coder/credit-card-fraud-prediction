version: '3.8'

services:
  # ==========================
  # 1. PostgreSQL (L∆∞u data demo)
  # ==========================
  postgres:
    image: postgres:13
    container_name: postgres
    environment:
      POSTGRES_USER: myuser
      POSTGRES_PASSWORD: mypass
      POSTGRES_DB: mydb
    ports:
      - "5432:5432" # ƒê√£ ƒë·ªïi v·ªÅ 5432 chu·∫©n ƒë·ªÉ d·ªÖ connect
    volumes:
      - pg_data:/var/lib/postgresql/data
    networks:
      - data-network
    mem_limit: 512m # Gi·ªõi h·∫°n RAM

  # ==========================
  # 2. MinIO (S3 Object Storage)
  # ==========================
  minio:
    image: minio/minio:latest
    container_name: minio
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: admin123
    ports:
      - "9000:9000" # API Port
      - "9001:9001" # Console UI Port
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    networks:
      - data-network
    mem_limit: 512m

  # ==========================
  # 3. Kafka Broker (KRaft Mode - No Zookeeper needed)
  # ==========================
  kafka-broker:
    image: confluentinc/cp-kafka:7.7.0
    container_name: kafka-broker
    environment:
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka-broker:9093
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://0.0.0.0:9094
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker:9092,EXTERNAL://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      CLUSTER_ID: "7Dvn0OLMQo-bg4qmCmflVg"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      # üëá Quan tr·ªçng: √âp Kafka ch·ªâ d√πng t·ªëi ƒëa 400MB RAM
      KAFKA_HEAP_OPTS: "-Xmx400m -Xms400m"
    ports:
      - "9092:9092"
      - "9094:9094"
    networks:
      - data-network
    mem_limit: 700m

  # ==========================
  # 4. Kafka UI
  # ==========================
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka-broker:9092
      KAFKA_CLUSTERS_0_READONLY: "false"
    ports:
      - "8085:8080" # ‚ö†Ô∏è ƒê·ªïi sang 8085 ƒë·ªÉ tr√°nh tr√πng Spark Master (8080)
    depends_on:
      - kafka-broker
    networks:
      - data-network
    mem_limit: 300m

  # ==========================
  # 5. Spark Master
  # ==========================
  spark-master:
    image: apache/spark:3.5.1
    container_name: spark-master
    hostname: spark-master
    command: >
      bash -c "/opt/spark/sbin/start-master.sh &&
               tail -f /opt/spark/logs/spark--org.apache.spark.deploy.master*.out"
    ports:
      - "8080:8080" # Spark UI
      - "7077:7077" # Master Port
    networks:
      - data-network
    mem_limit: 800m

  # ==========================
  # 6. Spark Worker (Ch·ªâ d√πng 1 c√°i cho nh·∫π m√°y)
  # ==========================
  spark-worker-1:
    image: apache/spark:3.5.1
    container_name: spark-worker-1
    hostname: spark-worker-1
    command: >
      bash -c "/opt/spark/sbin/start-worker.sh spark://spark-master:7077 &&
               tail -f /opt/spark/logs/spark--org.apache.spark.deploy.worker*.out"
    depends_on:
      - spark-master
    environment:
      SPARK_WORKER_MEMORY: "512m" # Gi·ªõi h·∫°n RAM cho Worker
    networks:
      - data-network
    mem_limit: 1g

  # ==========================
  # 7. Spark Client (ƒê·ªÉ submit job)
  # ==========================
  spark-client:
    image: apache/spark:3.5.1
    container_name: spark-client
    hostname: spark-client
    depends_on:
      - spark-master
    environment:
      SPARK_MASTER: "spark://spark-master:7077"
    volumes:
      - ./app:/opt/workspace/app
      - ./output:/opt/workspace/output
    command: tail -f /dev/null
    networks:
      - data-network

  # ==========================
  # 8. Airflow (Standalone Mode)
  # ==========================
  airflow:
    # D√πng image chu·∫©n ƒë·ªÉ kh√¥ng c·∫ßn build Dockerfile, ch·∫°y lu√¥n ƒë∆∞·ª£c
    image: apache/airflow:2.7.1
    container_name: airflow
    hostname: airflow
    command: standalone # Ch·∫°y c·∫£ Webserver + Scheduler trong 1 container cho nh·∫π
    environment:
      AIRFLOW__CORE__EXECUTOR: SequentialExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: sqlite:////opt/airflow/airflow.db
      _AIRFLOW_WWW_USER_CREATE: "true"
      _AIRFLOW_WWW_USER_USERNAME: "admin"
      _AIRFLOW_WWW_USER_PASSWORD: "admin"
    ports:
      - "8081:8080" # Airflow UI
    volumes:
      - ./airflow:/opt/airflow
      - ./app:/opt/workspace/app
    networks:
      - data-network
    mem_limit: 1.5g

volumes:
  pg_data:
  minio_data:

networks:
  data-network:
    driver: bridge
